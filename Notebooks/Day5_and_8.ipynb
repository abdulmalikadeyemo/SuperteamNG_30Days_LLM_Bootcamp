{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Human-in-the-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\n",
    "\n",
    "\n",
    "LangGraph supports `human-in-the-loop` workflows in a number of ways. In this section, we will use LangGraph's `interrupt_before` functionality to always break the tool node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1271c6090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[search_tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compile the graph, specifying to `interrupt_before` the `tools` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    \n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ tools, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (a9d6165b-b85d-445b-bff2-64731735a68a)\n",
      " Call ID: a9d6165b-b85d-445b-bff2-64731735a68a\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the graph state to confirm it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that unlike last time, the \"next\" node is set to 'tools'. We've interrupted here! Let's check the tool invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph'},\n",
       "  'id': 'a9d6165b-b85d-445b-bff2-64731735a68a',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query doesn't seem that reasonable but we will leave it as is. \n",
    "\n",
    "The simplest thing the human can do is just let the graph continue executing. Let's do that below.\n",
    "\n",
    "Next, continue the graph! Passing in `None` will just let the graph continue where it left off, without adding anything new to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (a9d6165b-b85d-445b-bff2-64731735a68a)\n",
      " Call ID: a9d6165b-b85d-445b-bff2-64731735a68a\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"LangGraph is a low-level framework that allows you to create stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. Learn how to use LangGraph with LangChain, LangSmith, and Anthropic tools to build agent and multi-agent workflows.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. It allows you to create stateful, flexible, and scalable systems with nodes, edges, and state management.\n",
      "\n",
      "With LangGraph, you can build stateful, multi-actor applications using LLMs, leveraging cycles, controllability, and persistence. You can use LangGraph in conjunction with other tools from the LangChain ecosystem, such as LangSmith and Anthropic, to create agent and multi-agent workflows.\n",
      "\n",
      "LangGraph provides a low-level framework for building complex applications, making it easier to manage state and interactions between agents. This enables you to focus on developing your application's logic without worrying about the underlying infrastructure.\n",
      "\n",
      "Some key features of LangGraph include:\n",
      "\n",
      "*   State management: LangGraph allows you to manage state across multiple nodes in your application, ensuring that each node has access to the necessary information.\n",
      "*   Cycles: LangGraph supports cycles, which enable you to create complex relationships between nodes and agents.\n",
      "*   Controllability: LangGraph provides controllability features, allowing you to control the flow of data and interactions between nodes.\n",
      "\n",
      "Overall, LangGraph is a powerful tool for building complex LLM applications. Its focus on state management, cycles, and controllability makes it an ideal choice for developers looking to create scalable and flexible systems.\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've used an `interrupt` to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. \n",
    "\n",
    "This opens up the potential UIs you can create with your AI systems. Since we have already added a checkpointer, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\n",
    "\n",
    "Next, we'll explore how to further customize the bot's behavior using custom state updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Manually Updating the State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we showed how to interrupt a graph so that a human could inspect its actions. This lets the human read the state, but if they want to change their agent's course, they'll need to have `write ` access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph lets you manually update state! Updating the state lets you control the agent's trajectory by modifying its actions (even modifying the past!). This capability is particularly useful when you want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal.\n",
    "\n",
    "We'll show how to update a checkpointed state below. As before, first, define your graph. We'll reuse the exact same graph as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt **after** actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")\n",
    "\n",
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (c5b5ff1b-6525-4e16-aed9-4c36a9534184)\n",
      " Call ID: c5b5ff1b-6525-4e16-aed9-4c36a9534184\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all of this is an exact repeat of the previous section. The LLM just requested to use the search engine tool and our graph was interrupted. If we proceed as before, the tool will be called to search the web.\n",
    "\n",
    "\n",
    "But what if the user wants to intercede? What if we think the chat bot doesn't need to use the tool?\n",
    "\n",
    "Let's directly provide the correct response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "\n",
      "Last 2 messages;\n",
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='8ccbe1d5-ef2f-47cc-840f-89672b38db6a', tool_call_id='c5b5ff1b-6525-4e16-aed9-4c36a9534184'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='b9eab86b-6100-431a-b098-98f1a5625169')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "answer = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",
    ")\n",
    "\n",
    "new_messages = [\n",
    "    # The LLM (API) expects some ToolMessage to match its tool call. We'll satisfy that here.\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n",
    "\n",
    "    # And then directly \"put words in the LLM's mouth\" by populating its response.\n",
    "    AIMessage(content=answer),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()\n",
    "graph.update_state(\n",
    "    # Which state to update\n",
    "    config,\n",
    "\n",
    "    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n",
    "    # to the existing state. We will review how to update existing messages in the next section!\n",
    "    {\"messages\": new_messages},\n",
    ")\n",
    "\n",
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Our new messages are appended to the messages already in the state. This is because of how we defined the State type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We annotated `messages` with the pre-built `add_messages` function. This instructs the graph to always append values to the existing list, rather than overwriting the list directly. The same logic is applied here, so the messages we passed to `update_state` were appended in the same way!\n",
    "\n",
    "\n",
    "\n",
    "The `update_state` function operates as if it were one of the nodes in your graph! By default, the update operation uses the node that was last executed, but you can manually specify it below. \n",
    "\n",
    "\n",
    "Let's add an update and tell the graph to treat it as if it came from the \"chatbot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efa7ecf-65cc-603e-8003-6928e455b9e3'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    config,\n",
    "    {\"messages\": [AIMessage(content=\"I'm an AI expert!\")]},\n",
    "    \n",
    "    # Which node for this function to act as. It will automatically continue\n",
    "    # processing as if this node just ran.\n",
    "    as_node=\"chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets inspect the current state as before to confirm the checkpoint reflects our manual updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='c0b8843f-2318-4605-a4c5-6d46dd749465', tool_call_id='18cbfb66-7b4c-4c48-8488-6588bd18be44'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='5545754b-d7be-4918-a3b4-c78dd9b41ecc'), AIMessage(content=\"I'm an AI expert!\", additional_kwargs={}, response_metadata={}, id='5fe10241-ab04-4579-96eb-76d8345ba322')]\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-3:])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='c0b8843f-2318-4605-a4c5-6d46dd749465', tool_call_id='18cbfb66-7b4c-4c48-8488-6588bd18be44'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', additional_kwargs={}, response_metadata={}, id='5545754b-d7be-4918-a3b4-c78dd9b41ecc'), AIMessage(content=\"I'm an AI expert!\", additional_kwargs={}, response_metadata={}, id='5fe10241-ab04-4579-96eb-76d8345ba322')]\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "print(snapshot.values[\"messages\"][-3:])\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** that we've continued to add AI messages to the state. Since we are acting as the chatbot and responding with an AIMessage that doesn't contain tool_calls, the graph knows that it has entered a finished state (next is empty)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **What if you want to overwrite existing messages?***\n",
    "\n",
    "The `add_messages` function we used to annotate our graph's `State` above controls how updates are made to the `messages` key. This function looks at any message IDs in the new `messages` list. If the ID matches a message in the existing state, `add_messages` overwrites the existing message with the new content.\n",
    "\n",
    "As an example, let's update the tool invocation to make sure we get good results from our search engine! \n",
    "\n",
    "First, start a new thread:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (1ab6e1c1-4abe-43df-a0b6-0543586d68ca)\n",
      " Call ID: 1ab6e1c1-4abe-43df-a0b6-0543586d68ca\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next,** let's update the tool invocation for our agent. Maybe we want to make the search more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Message ID run-28bfa347-4ec5-4ea7-aed5-841992873c05-0\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': '1ab6e1c1-4abe-43df-a0b6-0543586d68ca', 'type': 'tool_call'}\n",
      "Updated\n",
      "{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph framework for language models'}, 'id': '1ab6e1c1-4abe-43df-a0b6-0543586d68ca', 'type': 'tool_call'}\n",
      "Message ID run-28bfa347-4ec5-4ea7-aed5-841992873c05-0\n",
      "\n",
      "\n",
      "Tool calls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph framework for language models'},\n",
       "  'id': '1ab6e1c1-4abe-43df-a0b6-0543586d68ca',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(\"Original\")\n",
    "print(\"Message ID\", existing_message.id)\n",
    "print(existing_message.tool_calls[0])\n",
    "\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "new_tool_call[\"args\"][\"query\"] = \"LangGraph framework for language models\"\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(\"Updated\")\n",
    "print(new_message.tool_calls[0])\n",
    "print(\"Message ID\", new_message.id)\n",
    "graph.update_state(config, {\"messages\": [new_message]})\n",
    "\n",
    "print(\"\\n\\nTool calls\")\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've modified the AI's tool invocation to search for \"LangGraph framework for language models\" instead of the simple \"LangGraph\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resume the graph by streaming with an input of `None` and the existing config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (1ab6e1c1-4abe-43df-a0b6-0543586d68ca)\n",
      " Call ID: 1ab6e1c1-4abe-43df-a0b6-0543586d68ca\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph's flexible framework supports diverse control flows - single agent, multi-agent, hierarchical, sequential - and robustly handles realistic, complex scenarios. Ensure reliability with easy-to-add moderation and quality loops that prevent agents from veering off course. Use LangGraph Platform to templatize your cognitive\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a flexible framework for building stateful, multi-actor applications with language models (LLMs). It provides a robust platform for creating agent and multi-agent workflows, offering several core benefits compared to other LLM frameworks. Some of the key features of LangGraph include:\n",
      "\n",
      "1. **Cycles**: LangGraph allows you to define flows that involve cycles, which is essential for most agentic architectures.\n",
      "2. **Controllability**: The framework provides controllability, enabling you to manage and moderate agent behavior.\n",
      "3. **Persistence**: LangGraph ensures persistence, allowing agents to maintain their state across different interactions.\n",
      "\n",
      "LangGraph supports diverse control flows, including single-agent, multi-agent, hierarchical, and sequential workflows. It also offers easy-to-add moderation and quality loops to prevent agents from veering off course.\n",
      "\n",
      "The LangGraph Platform provides a templatized approach to building cognitive architectures, making it easier to create and deploy complex scenarios. Overall, LangGraph is a powerful tool for building robust and reliable multi-agent applications with LLMs.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The graph queries the search engine using our updated query term - we were able to manually override the LLM's search here!\n",
    "\n",
    "\n",
    "All of this is reflected in the graph's checkpointed memory, meaning if we continue the conversation, it will recall all the modified state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember what I'm learning about?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (bf6ccc6c-67c9-4a4a-aff4-c3b3bb69bab9)\n",
      " Call ID: bf6ccc6c-67c9-4a4a-aff4-c3b3bb69bab9\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"Remember what I'm learning about?\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the LLM isn't smart enough to understand that it doesn't need to call a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (bf6ccc6c-67c9-4a4a-aff4-c3b3bb69bab9)\n",
      " Call ID: bf6ccc6c-67c9-4a4a-aff4-c3b3bb69bab9\n",
      "  Args:\n",
      "    query: LangGraph framework for language models\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://medium.com/@monsuralirana/langgraph-vs-langchain-vs-langflow-vs-langsmith-which-one-to-use-why-69ee91e91000\", \"content\": \"LangGraph is a powerful framework for developers focused on designing complex language model pipelines using an agentic approach, rather than purely visual representation.\"}, {\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're learning about LangGraph, a framework for building stateful, multi-actor applications with language models (LLMs). Specifically, you're looking into how LangGraph can be used to create agent and multi-agent workflows.\n",
      "\n",
      "To recap, LangGraph is a powerful tool that offers several core benefits compared to other LLM frameworks. These include:\n",
      "\n",
      "1. **Cycles**: The ability to define flows that involve cycles, which is essential for most agentic architectures.\n",
      "2. **Controllability**: The framework provides controllability, enabling you to manage and moderate agent behavior.\n",
      "3. **Persistence**: LangGraph ensures persistence, allowing agents to maintain their state across different interactions.\n",
      "\n",
      "LangGraph supports diverse control flows, including single-agent, multi-agent, hierarchical, and sequential workflows. It also offers easy-to-add moderation and quality loops to prevent agents from veering off course.\n",
      "\n",
      "Is there anything specific you'd like to know about LangGraph or its applications?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's It!**\n",
    "\n",
    "You've used `interrupt_before` and `update_state` to manually modify the state as a part of a human-in-the-loop workflow. Interruptions and state modifications let you control how the agent behaves. Combined with persistent checkpointing, it means you can `pause` an action and `resume` at any point. Your user doesn't have to be available when the graph interrupts!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph code for this section is identical to previous ones. The key snippets to remember are to add `.compile(..., interrupt_before=[...])` `(or interrupt_after)` if you want to explicitly pause the graph whenever it reaches a node. \n",
    "\n",
    "Then you can use `update_state` to modify the checkpoint and control how the graph should proceed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Customizing State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've relied on a simple state (it's just a list of messages!). \n",
    "\n",
    "You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. \n",
    "\n",
    "\n",
    "In this section, we will extend our chat bot with a new node to illustrate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, we involved a human deterministically: the graph always interrupted whenever an tool was invoked. \n",
    "\n",
    "\n",
    "What if we wanted our chat bot to have the choice of relying on a human?\n",
    "\n",
    "One way to do this is to create a passthrough \"human\" node, before which the graph will always stop. We will only execute this node if the LLM invokes a \"human\" tool. \n",
    "\n",
    "For our convenience, we will include an `\"ask_human\"` flag in our graph state that we will flip if the LLM calls this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, define the new graph, with an updated State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "    # This flag is new\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define a schema to show the model to let it decide to request assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "This notebook uses Pydantic v2 `BaseModel`, which requires `langchain-core >= 0.3`. Using `langchain-core < 0.3` will result in errors due to mixing of Pydantic v1 and v2 `BaseModels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-core\n",
      "Version: 0.3.19\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/user/miniforge3/envs/LLM_Bootcamp/lib/python3.11/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity, typing-extensions\n",
      "Required-by: langchain, langchain-anthropic, langchain-community, langchain-groq, langchain-ollama, langchain-openai, langchain-text-splitters, langgraph, langgraph-checkpoint\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the chatbot node. \n",
    "\n",
    "The primary modification here is flip the `ask_human` flag if we see that the chat bot has invoked the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    ask_human = False\n",
    "\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        \n",
    "        ask_human = True\n",
    "        \n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the graph builder and add the chatbot and tools nodes to the graph, same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11ef10950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the `\"human\"` node. This `node` function is mostly a placeholder in our graph that will trigger an interrupt. \n",
    "\n",
    "If the human does **not** manually update the state during the `interrupt`, it inserts a tool message so the LLM knows the user was requested but didn't respond. \n",
    "\n",
    "This node also unsets the `ask_human` flag so the graph knows not to revisit the node unless further requests are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11ef10950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "        \n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the conditional logic. \n",
    "\n",
    "The `select_next_node` will route to the `human` node if the flag is set. Otherwise, it lets the prebuilt `tools_condition` function choose the next node.\n",
    "\n",
    "Recall that the `tools_condition` function simply checks to see if the `chatbot` has responded with any tool_calls in its response message. If so, it routes to the action node. Otherwise, it ends the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11ef10950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add the simple directed edges and compile the graph. These edges instruct the graph to always flow from node `a->b` whenever `a` finishes executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "\n",
    "    # We interrupt before 'human' here instead. So, whenever a human is requested, we interrupt\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the graph structure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat bot can either request help from a human (chatbot->select->human), or invoke the search engine tool (chatbot->select->action), or directly respond (chatbot->select->end). \n",
    "\n",
    "\n",
    "Once an action or request has been made, the graph will transition back to the chatbot node to continue operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this graph in action. \n",
    "\n",
    "\n",
    "We will request for expert assistance to illustrate our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building this AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  RequestAssistance (75451ffa-8441-472a-ae2b-221225e13f14)\n",
      " Call ID: 75451ffa-8441-472a-ae2b-221225e13f14\n",
      "  Args:\n",
      "    request: building an AI agent\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I need some expert guidance for building this AI agent. Could you request assistance for me?\"\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** the LLM has invoked the `\"RequestAssistance\"` tool we provided it, and the interrupt has been set. \n",
    "\n",
    "Let's inspect the graph state to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human',)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph state is indeed interrupted before the 'human' node. We can act as the \"expert\" in this scenario and manually update the state by adding a new ToolMessage with our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, respond to the chatbot's request by: \n",
    "\n",
    "1. Creating a `ToolMessage` with our response. This will be passed back to the `chatbot`. \n",
    "\n",
    "2. Calling `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efa829a-a1b6-63b4-8002-99265b82be6b'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the state to confirm our response was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='I need some expert guidance for building this AI agent. Could you request assistance for me?', additional_kwargs={}, response_metadata={}, id='05611438-a2d8-4b28-8d17-8e26fa9d0695'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-11-21T16:33:49.734333Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'RequestAssistance', 'arguments': {'request': 'building an AI agent'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 4829414333, 'load_duration': 813843833, 'prompt_eval_count': 293, 'prompt_eval_duration': 3773000000, 'eval_count': 21, 'eval_duration': 239000000}, id='run-e0af69b1-3d9c-4ccc-9431-3592ef2e0ea1-0', tool_calls=[{'name': 'RequestAssistance', 'args': {'request': 'building an AI agent'}, 'id': '75451ffa-8441-472a-ae2b-221225e13f14', 'type': 'tool_call'}], usage_metadata={'input_tokens': 293, 'output_tokens': 21, 'total_tokens': 314}),\n",
       " ToolMessage(content=\"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\", id='cc969fe8-5373-4502-ad5d-9ca50d63fc3a', tool_call_id='75451ffa-8441-472a-ae2b-221225e13f14')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, **resume** the graph by invoking it with `None` as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems like we've requested assistance for building an AI agent. Based on our conversation, it appears that we're looking into using LangGraph as a potential solution.\n",
      "\n",
      "LangGraph is a popular open-source framework for building and training neural networks. It's designed to be highly flexible and extensible, making it well-suited for complex tasks like building an AI agent.\n",
      "\n",
      "To get started with LangGraph, you'll need to:\n",
      "\n",
      "1. Install the required dependencies: This includes Python 3.8 or later, TensorFlow 2.x, and PyTorch.\n",
      "2. Choose a suitable architecture: LangGraph supports a range of architectures, including recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and transformer models.\n",
      "3. Train your model: Once you've chosen an architecture, you'll need to train it on your dataset. This involves defining a loss function, optimizer, and evaluation metric.\n",
      "\n",
      "Some popular libraries for working with LangGraph include:\n",
      "\n",
      "* `langgraph.models`: Provides pre-built models and architectures for common tasks like language translation and text classification.\n",
      "* `langgraph.layers`: Offers a range of customizable layers for building your own models.\n",
      "* `langgraph.utils`: Includes tools for data preprocessing, visualization, and evaluation.\n",
      "\n",
      "If you're new to LangGraph, we recommend checking out the official documentation and tutorials to get started. Additionally, there are many online resources and communities available for support and guidance.\n",
      "\n",
      "Is there anything specific you'd like to know about getting started with LangGraph?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice** that the chat bot has incorporated the updated state in its final response. \n",
    "\n",
    "Since everything was checkpointed, the \"expert\" human in the loop could perform the update at any time without impacting the graph's execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's It! \n",
    "\n",
    "You've now added an additional node to your assistant graph to let the chat bot decide for itself whether or not it needs to interrupt execution. You did so by updating the graph `State` with a new `ask_human` field and modifying the interruption logic when compiling the graph. \n",
    "\n",
    "This lets you dynamically include a human in the loop while maintaining full memory every time you execute the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and manually override the state to control future responses.\n",
    "\n",
    "But what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant's work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\n",
    "\n",
    "You can create both of these experiences and more using LangGraph's built-in `\"time travel\"` functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will \"rewind\" your graph by fetching a checkpoint using the graph's `get_state_history` method. \n",
    "\n",
    "You can then resume execution at this previous point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, recall our chatbot graph.**\n",
    "\n",
    "Note: We don't need to make any changes from before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "# NOTE: you must use langchain-core >= 0.3 with Pydantic v2\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # This flag is new\n",
    "    ask_human: bool\n",
    "\n",
    "\n",
    "class RequestAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation to an expert. Use this if you are unable to assist directly or if the user requires support beyond your permissions.\n",
    "\n",
    "    To use this function, relay the user's 'request' so the expert can provide the right guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str\n",
    "\n",
    "\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "tools = [search_tool]\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "# We can bind the llm to a tool definition, a pydantic model, or a json schema\n",
    "llm_with_tools = llm.bind_tools(tools + [RequestAssistance])\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    ask_human = False\n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == RequestAssistance.__name__\n",
    "    ):\n",
    "        ask_human = True\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "\n",
    "\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # Typically, the user will have updated the state during the interrupt.\n",
    "        # If they choose not to, we will include a placeholder ToolMessage to\n",
    "        # let the LLM continue.\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Append the new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Unset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "\n",
    "def select_next_node(state: State):\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, we can route as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", END: END},\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have our graph take a couple steps. \n",
    "\n",
    "Note: Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (f3451b37-5d0e-4154-a8b1-1317d2d5d523)\n",
      " Call ID: f3451b37-5d0e-4154-a8b1-1317d2d5d523\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/\", \"content\": \"LangGraph is a framework for creating stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. Learn how to use LangGraph with LangChain, LangSmith, and Anthropic tools to build agent and multi-agent workflows.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the tool call response, here's a formatted answer to your original question:\n",
      "\n",
      "LangGraph is a framework for creating stateful, multi-actor applications with Large Language Models (LLMs), using cycles, controllability, and persistence. It is part of the LangChain ecosystem and simplifies the development of complex, multi-agent LLM applications.\n",
      "\n",
      "With LangGraph, you can create systems that are flexible, scalable, and easy to manage. The framework uses nodes, edges, and state management to enable the creation of stateful, multi-actor applications.\n",
      "\n",
      "LangGraph is particularly useful for building agent and multi-agent workflows using tools like LangChain, LangSmith, and Anthropic. If you're looking to learn more about LangGraph, I recommend checking out the official documentation or taking a tutorial on DataCamp.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"I'm learning LangGraph. Could you do some research on it for me?\")\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You see! It's sloppy. It should not have requested for Human input**\n",
    "\n",
    "We will see how to fix this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  RequestAssistance (ec902874-b9aa-4f69-965c-59b05aecb1fe)\n",
      " Call ID: ec902874-b9aa-4f69-965c-59b05aecb1fe\n",
      "  Args:\n",
      "    request: I want to build an autonomous agent using LangGraph and need guidance on how to get started\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No response from human.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the tool call response, here's a formatted answer to your original question:\n",
      "\n",
      "Building an autonomous agent with LangGraph sounds like an exciting project! To get started, you'll want to familiarize yourself with the basics of LangGraph and its components.\n",
      "\n",
      "First, let's break down the key concepts:\n",
      "\n",
      "1. **Nodes**: Represent individual agents or entities in your system.\n",
      "2. **Edges**: Define interactions between nodes, representing relationships or dependencies.\n",
      "3. **State management**: Handle changes to node states over time.\n",
      "\n",
      "To build an autonomous agent, you'll need to:\n",
      "\n",
      "1. **Define your problem space**: Identify the specific tasks or goals for your agent.\n",
      "2. **Design your architecture**: Choose a suitable node and edge structure for your system.\n",
      "3. **Implement state management**: Use LangGraph's built-in features or custom solutions to manage changes to node states.\n",
      "\n",
      "LangGraph provides various tools and libraries to help you get started, such as:\n",
      "\n",
      "1. **LangChain**: A suite of tools for building agent workflows.\n",
      "2. **LangSmith**: A library for creating agents with a focus on explainability and transparency.\n",
      "\n",
      "For more guidance, I recommend checking out the official LangGraph documentation, LangChain tutorials, or exploring open-source examples on GitHub. Additionally, consider joining online communities or forums to connect with other developers working on similar projects.\n",
      "\n",
      "How would you like to proceed with your autonomous agent project?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've had the agent take a couple steps, we can `replay` the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('human',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Checkpoints are saved for every step of the graph. \n",
    "\n",
    "This spans invocations so you can rewind across a full thread's history. \n",
    "\n",
    "We've picked out `to_replay` as a state to resume from. This is the state after the `chatbot` node in the second graph invocation above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resuming from this point should call the `human` node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('human',)\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa8346-af04-65be-8006-b091f19f0c7d'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The checkpoint's config `(to_replay.config)` contains a `checkpoint_id` timestamp.\n",
    "\n",
    "Providing this `checkpoint_id` value tells LangGraph's checkpointer to load the state from that moment in time. \n",
    "\n",
    "Let's try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  RequestAssistance (ec902874-b9aa-4f69-965c-59b05aecb1fe)\n",
      " Call ID: ec902874-b9aa-4f69-965c-59b05aecb1fe\n",
      "  Args:\n",
      "    request: I want to build an autonomous agent using LangGraph and need guidance on how to get started\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No response from human.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the tool call response, here's a formatted answer to your original question:\n",
      "\n",
      "Building an autonomous agent with LangGraph sounds like an exciting project! To get started, you'll want to familiarize yourself with the basics of LangGraph and its components.\n",
      "\n",
      "First, let's break down the key concepts:\n",
      "\n",
      "1. **Nodes**: Represent individual agents or entities in your system.\n",
      "2. **Edges**: Define interactions between nodes, representing relationships or dependencies.\n",
      "3. **State management**: Handle changes to node states over time.\n",
      "\n",
      "To build an autonomous agent, you'll need to:\n",
      "\n",
      "1. **Define your problem space**: Identify the specific tasks or goals for your agent.\n",
      "2. **Design your architecture**: Choose a suitable node and edge structure for your system.\n",
      "3. **Implement state management**: Use LangGraph's built-in features or custom solutions to manage changes to node states.\n",
      "\n",
      "LangGraph provides various tools and libraries to help you get started, such as:\n",
      "\n",
      "1. **LangChain**: A suite of tools for building agent workflows.\n",
      "2. **LangSmith**: A library for creating agents with a focus on explainability and transparency.\n",
      "\n",
      "For more guidance, I recommend checking out the official LangGraph documentation, LangChain tutorials, or exploring open-source examples on GitHub. Additionally, consider joining online communities or forums to connect with other developers working on similar projects.\n",
      "\n",
      "How would you like to proceed with your autonomous agent project?\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the graph resumed execution from the **human** node. \n",
    "\n",
    "You can tell this is the case since the first value printed above is the default response from the `ToolMessage` which indicates that the human did not respond.\n",
    "\n",
    "\n",
    "Thats it! You've now used time-travel checkpoint traversal in LangGraph. \n",
    "\n",
    "Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Depending on the LLM used, the output and behavior of your graph may vary.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
